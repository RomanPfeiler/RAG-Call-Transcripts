{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180dfd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with Kernel: gemini-chat-env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20be452d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Imports\n",
    "# ==============================================================================\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import random\n",
    "from typing import List, Dict, Any\n",
    "from google import genai\n",
    "from google.genai import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5860fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# API key\n",
    "# ==============================================================================\n",
    "def read_key_from_env_file(filename: str = \"key.env\", var_name: str = \"GEMINI_API_KEY\") -> str:\n",
    "    p = Path.cwd() / filename  # current working directory (your notebook folder)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"'{filename}' not found in {Path.cwd()}\")\n",
    "    for line in p.read_text(encoding=\"utf-8\").splitlines():\n",
    "        line = line.strip()\n",
    "        if not line or line.startswith(\"#\"):\n",
    "            continue\n",
    "        if \"=\" in line:\n",
    "            k, v = line.split(\"=\", 1)\n",
    "            if k.strip() == var_name:\n",
    "                return v.strip().strip('\"').strip(\"'\")\n",
    "    raise RuntimeError(f\"{var_name} not found in {filename}\")\n",
    "\n",
    "API_KEY = read_key_from_env_file() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a893d207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Model selection\n",
    "# ==============================================================================\n",
    "EMBED_MODEL = \"gemini-embedding-001\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8436987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Config\n",
    "# ==============================================================================\n",
    "INPUT_PKL  = \"repackaged_transcript_data.pkl\"\n",
    "OUTPUT_PKL = \"transcript_embeddings.pkl\"\n",
    "\n",
    "CUSTOMERS_TO_PROCESS = 50\n",
    "SLEEP_SECONDS = 1.0       # base delay after successful call\n",
    "MAX_RETRIES   = 6         # for 503/429/timeouts\n",
    "BACKOFF_BASE  = 1.6       # exponential backoff base\n",
    "BACKOFF_CAP   = 30.0      # max sleep per retry\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34cb1894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Helpers\n",
    "# ==============================================================================\n",
    "def atomic_pickle(obj, path: str):\n",
    "    tmp = path + \".tmp\"\n",
    "    with open(tmp, \"wb\") as f:\n",
    "        pickle.dump(obj, f)\n",
    "    os.replace(tmp, path)\n",
    "\n",
    "def load_input() -> List[List[str]]:\n",
    "    with open(INPUT_PKL, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def load_existing() -> List[Dict[str, Any]]:\n",
    "    if not os.path.exists(OUTPUT_PKL):\n",
    "        return []\n",
    "    with open(OUTPUT_PKL, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def embed_one(client: genai.Client, text: str) -> List[float]:\n",
    "    \"\"\"\n",
    "    Embed a transcript (document) for RAG using RETRIEVAL_DOCUMENT.\n",
    "    Returns a 3072-d vector (list[float]) to match your stored shape.\n",
    "    \"\"\"\n",
    "    cfg = types.EmbedContentConfig(\n",
    "        task_type=\"RETRIEVAL_DOCUMENT\",\n",
    "        output_dimensionality=3072,  # keep consistent with your store\n",
    "    )\n",
    "\n",
    "    last_err = None\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            r = client.models.embed_content(\n",
    "                model=EMBED_MODEL,\n",
    "                contents=text,\n",
    "                config=cfg,\n",
    "            )\n",
    "            return r.embeddings[0].values  # 3072-d vector\n",
    "        except Exception as e:\n",
    "            msg = str(e)\n",
    "            if \"FreeTier\" in msg and \"limit: 0\" in msg:\n",
    "                raise RuntimeError(\n",
    "                    \"Embedding FreeTier is 0/Unavailable. Enable billing or switch project.\"\n",
    "                )\n",
    "            if any(s in msg for s in (\"503\", \"UNAVAILABLE\", \"overloaded\", \"429\", \"timeout\", \"Deadline\")):\n",
    "                sleep_s = min(BACKOFF_BASE ** attempt + random.random(), BACKOFF_CAP)\n",
    "                time.sleep(sleep_s)\n",
    "                last_err = e\n",
    "                continue\n",
    "            raise\n",
    "    raise last_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d6f23b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50 customer records from 'repackaged_transcript_data.pkl'.\n",
      "ðŸš€ Starting (resume) for 50 customers; already done: 0\n",
      "âœ… Processed customer 1/50\n",
      "âœ… Processed customer 2/50\n",
      "âœ… Processed customer 3/50\n",
      "âœ… Processed customer 4/50\n",
      "âœ… Processed customer 5/50\n",
      "âœ… Processed customer 6/50\n",
      "âœ… Processed customer 7/50\n",
      "âœ… Processed customer 8/50\n",
      "âœ… Processed customer 9/50\n",
      "âœ… Processed customer 10/50\n",
      "âœ… Processed customer 11/50\n",
      "âœ… Processed customer 12/50\n",
      "âœ… Processed customer 13/50\n",
      "âœ… Processed customer 14/50\n",
      "âœ… Processed customer 15/50\n",
      "âœ… Processed customer 16/50\n",
      "âœ… Processed customer 17/50\n",
      "âœ… Processed customer 18/50\n",
      "âœ… Processed customer 19/50\n",
      "âœ… Processed customer 20/50\n",
      "âœ… Processed customer 21/50\n",
      "âœ… Processed customer 22/50\n",
      "âœ… Processed customer 23/50\n",
      "âœ… Processed customer 24/50\n",
      "âœ… Processed customer 25/50\n",
      "âœ… Processed customer 26/50\n",
      "âœ… Processed customer 27/50\n",
      "âœ… Processed customer 28/50\n",
      "âœ… Processed customer 29/50\n",
      "âœ… Processed customer 30/50\n",
      "âœ… Processed customer 31/50\n",
      "âœ… Processed customer 32/50\n",
      "âœ… Processed customer 33/50\n",
      "âœ… Processed customer 34/50\n",
      "âœ… Processed customer 35/50\n",
      "âœ… Processed customer 36/50\n",
      "âœ… Processed customer 37/50\n",
      "âœ… Processed customer 38/50\n",
      "âœ… Processed customer 39/50\n",
      "âœ… Processed customer 40/50\n",
      "âœ… Processed customer 41/50\n",
      "âœ… Processed customer 42/50\n",
      "âœ… Processed customer 43/50\n",
      "âœ… Processed customer 44/50\n",
      "âœ… Processed customer 45/50\n",
      "âœ… Processed customer 46/50\n",
      "âœ… Processed customer 47/50\n",
      "âœ… Processed customer 48/50\n",
      "âœ… Processed customer 49/50\n",
      "âœ… Processed customer 50/50\n",
      "\n",
      "Done. Saved 50 customers to 'transcript_embeddings.pkl'.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Main\n",
    "# ==============================================================================\n",
    "def main():\n",
    "    # Client\n",
    "    client = genai.Client(api_key=API_KEY)\n",
    "\n",
    "    # Load input\n",
    "    try:\n",
    "        customer_data = load_input()\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Could not find '{INPUT_PKL}'. Make sure the file exists.\")\n",
    "    print(f\"Loaded {len(customer_data)} customer records from '{INPUT_PKL}'.\")\n",
    "\n",
    "    # Resume support: load existing output and build set of done ids\n",
    "    processed = load_existing()\n",
    "    done_ids = {rec[\"customer_id\"] for rec in processed}\n",
    "    total = min(CUSTOMERS_TO_PROCESS, len(customer_data))\n",
    "    print(f\"ðŸš€ Starting (resume) for {total} customers; already done: {len(done_ids)}\")\n",
    "\n",
    "    for i, transcripts in enumerate(customer_data[:total]):\n",
    "        if i in done_ids:\n",
    "            print(f\"â†©ï¸  Skipping customer {i+1}/{total} (already processed)\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            embs = []\n",
    "            for t in transcripts:\n",
    "                embs.append(embed_one(client, t))\n",
    "                time.sleep(SLEEP_SECONDS)\n",
    "\n",
    "            rec = {\"customer_id\": i, \"transcripts\": transcripts, \"embeddings\": embs}\n",
    "            processed.append(rec)\n",
    "\n",
    "            # Save after each customer (atomic) so we can safely resume later\n",
    "            atomic_pickle(processed, OUTPUT_PKL)\n",
    "            print(f\"âœ… Processed customer {i+1}/{total}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"â›” Stopping on customer {i+1}. Details:\\n{e}\")\n",
    "            break\n",
    "\n",
    "    print(f\"\\nDone. Saved {len(processed)} customers to '{OUTPUT_PKL}'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46ccc9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 50 customer records from 'transcript_embeddings.pkl'.\n",
      "âœ… All records have 4 transcripts and 4 embeddings.\n",
      "ðŸ“ Embedding dimension(s) present: [3072] (expected single value, typically 3072)\n",
      "ðŸ“Š Embedding L2-norm â€” mean: 1.000, min: 1.000, max: 1.000\n",
      "ðŸ“ Transcript length (chars) â€” mean: 2334.2, median: 2245, min: 1899, max: 3426\n",
      "\n",
      "ðŸ”Ž Intra-customer cosine similarity matrices (first up to 3 customers):\n",
      "\n",
      "Customer 0 (4x4 cosine):\n",
      "[[1.    0.8   0.788 0.793]\n",
      " [0.8   1.    0.753 0.737]\n",
      " [0.788 0.753 1.    0.853]\n",
      " [0.793 0.737 0.853 1.   ]]\n",
      "\n",
      "Customer 1 (4x4 cosine):\n",
      "[[1.    0.781 0.784 0.779]\n",
      " [0.781 1.    0.802 0.799]\n",
      " [0.784 0.802 1.    0.906]\n",
      " [0.779 0.799 0.906 1.   ]]\n",
      "\n",
      "Customer 2 (4x4 cosine):\n",
      "[[1.    0.82  0.804 0.806]\n",
      " [0.82  1.    0.821 0.808]\n",
      " [0.804 0.821 1.    0.874]\n",
      " [0.806 0.808 0.874 1.   ]]\n",
      "\n",
      "ðŸ§ª Sample record 0 overview:\n",
      "  customer_id: 0\n",
      "  transcript[0]: 2006 chars | Thank you for calling [ORGANIZATION] [ORGANIZATION] [ORGANIZATION], [ORGANIZATION]. This is [PERSON_NAME] speaking. How can I help you? Hi, Mr. [PERSON_NAME], please speak to Mr. [â€¦\n",
      "  transcript[1]: 2091 chars | Thank you for calling [ORGANIZATION] [ORGANIZATION]. This call is being recorded. Please hold for the next available [OCCUPATION] class, and neighborly company. This is [PERSON_NAMâ€¦\n",
      "  transcript[2]: 2185 chars | Hello? Yes, this is [PERSON_NAME]. How are you doing today? I'm doing fine, and you? I'm fine. Thank you so much for asking. God bless to you. The reason of my call is just to let â€¦\n",
      "  transcript[3]: 2895 chars | Hello? Hello? Hello? Hello, Hi, this is [PERSON_NAME]. [PERSON_NAME], I'm sorry to bother you right now because upon processing your benefit for braces, it says here that the Medicâ€¦\n",
      "  embedding[0]: dim=3072  norm=1.000\n",
      "  embedding[1]: dim=3072  norm=1.000\n",
      "  embedding[2]: dim=3072  norm=1.000\n",
      "  embedding[3]: dim=3072  norm=1.000\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Check file contents\n",
    "# ==============================================================================\n",
    "import statistics\n",
    "from typing import List, Dict, Any\n",
    "import numpy as np\n",
    "\n",
    "INPUT_PKL = \"transcript_embeddings.pkl\"\n",
    "\n",
    "def load_pickle(path: str) -> List[Dict[str, Any]]:\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def cosine_matrix(X: np.ndarray) -> np.ndarray:\n",
    "    # X: (n, d)\n",
    "    norms = np.linalg.norm(X, axis=1, keepdims=True) + 1e-12\n",
    "    Xn = X / norms\n",
    "    return Xn @ Xn.T  # (n, n)\n",
    "\n",
    "def main():\n",
    "    data = load_pickle(INPUT_PKL)\n",
    "    n_customers = len(data)\n",
    "    print(f\"âœ… Loaded {n_customers} customer records from '{INPUT_PKL}'.\")\n",
    "\n",
    "    # Validate structure and collect stats\n",
    "    bad_struct = []\n",
    "    dims = []\n",
    "    norms = []\n",
    "    lens_chars = []\n",
    "\n",
    "    for rec_idx, rec in enumerate(data):\n",
    "        if not isinstance(rec, dict):\n",
    "            bad_struct.append((rec_idx, \"record not dict\"))\n",
    "            continue\n",
    "\n",
    "        cid = rec.get(\"customer_id\")\n",
    "        transcripts = rec.get(\"transcripts\")\n",
    "        embeddings = rec.get(\"embeddings\")\n",
    "\n",
    "        if not isinstance(transcripts, list) or len(transcripts) != 4:\n",
    "            bad_struct.append((cid, \"transcripts != 4\"))\n",
    "        if not isinstance(embeddings, list) or len(embeddings) != 4:\n",
    "            bad_struct.append((cid, \"embeddings != 4\"))\n",
    "\n",
    "        # Stats\n",
    "        for t in (transcripts or []):\n",
    "            if isinstance(t, str):\n",
    "                lens_chars.append(len(t))\n",
    "\n",
    "        for v in (embeddings or []):\n",
    "            if isinstance(v, (list, tuple, np.ndarray)):\n",
    "                dims.append(len(v))\n",
    "                norms.append(float(np.linalg.norm(np.asarray(v, dtype=np.float32))))\n",
    "\n",
    "    if bad_struct:\n",
    "        print(f\"âš ï¸ Found {len(bad_struct)} structural issues (showing up to 5): {bad_struct[:5]}\")\n",
    "    else:\n",
    "        print(\"âœ… All records have 4 transcripts and 4 embeddings.\")\n",
    "\n",
    "    if dims:\n",
    "        unique_dims = sorted(set(dims))\n",
    "        print(f\"ðŸ“ Embedding dimension(s) present: {unique_dims} (expected single value, typically 3072)\")\n",
    "    if norms:\n",
    "        print(f\"ðŸ“Š Embedding L2-norm â€” mean: {statistics.mean(norms):.3f}, \"\n",
    "              f\"min: {min(norms):.3f}, max: {max(norms):.3f}\")\n",
    "\n",
    "    if lens_chars:\n",
    "        print(f\"ðŸ“ Transcript length (chars) â€” mean: {statistics.mean(lens_chars):.1f}, \"\n",
    "              f\"median: {statistics.median(lens_chars):.0f}, min: {min(lens_chars)}, max: {max(lens_chars)}\")\n",
    "\n",
    "    # Quick per-customer similarity glance for the first 3 customers\n",
    "    print(\"\\nðŸ”Ž Intra-customer cosine similarity matrices (first up to 3 customers):\")\n",
    "    for rec in data[:3]:\n",
    "        cid = rec[\"customer_id\"]\n",
    "        E = np.array(rec[\"embeddings\"], dtype=np.float32)  # (4, d)\n",
    "        C = cosine_matrix(E)\n",
    "        np.set_printoptions(precision=3, suppress=True)\n",
    "        print(f\"\\nCustomer {cid} (4x4 cosine):\\n{C}\")\n",
    "\n",
    "    # Show one example record (truncated text) to confirm alignment\n",
    "    if n_customers:\n",
    "        r0 = data[0]\n",
    "        print(\"\\nðŸ§ª Sample record 0 overview:\")\n",
    "        for k in (\"customer_id\",):\n",
    "            print(f\"  {k}: {r0[k]}\")\n",
    "        for idx, t in enumerate(r0[\"transcripts\"]):\n",
    "            excerpt = (t[:180] + \"â€¦\") if len(t) > 180 else t\n",
    "            print(f\"  transcript[{idx}]: {len(t)} chars | {excerpt}\")\n",
    "        for idx, v in enumerate(r0[\"embeddings\"]):\n",
    "            print(f\"  embedding[{idx}]: dim={len(v)}  norm={np.linalg.norm(np.asarray(v, dtype=np.float32)):.3f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640a102c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemini-chat-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
