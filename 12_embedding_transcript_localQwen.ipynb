{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a9eab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.5 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"c:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 519, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 508, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 400, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 602, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\pfeil\\AppData\\Local\\Temp\\ipykernel_22388\\2457372103.py\", line 7, in <module>\n",
      "    import torch # Imported to manage CPU/GPU settings if needed\n",
      "  File \"c:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\site-packages\\torch\\__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"c:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\site-packages\\torch\\functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"c:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\site-packages\\torch\\nn\\__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"c:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\site-packages\\torch\\nn\\modules\\__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"c:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\site-packages\\torch\\nn\\modules\\transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "c:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "c:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Imports\n",
    "# ==============================================================================\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import torch # Imported to manage CPU/GPU settings if needed\n",
    "from typing import List, Dict, Any\n",
    "from pathlib import Path\n",
    "\n",
    "# NEW: Import the library needed for local Hugging Face models\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ==============================================================================\n",
    "# Config\n",
    "# ==============================================================================\n",
    "# File paths for your data\n",
    "INPUT_PKL  = \"repackaged_transcript_data.pkl\"\n",
    "OUTPUT_PKL = \"transcript_embeddings.pkl\"\n",
    "\n",
    "# Processing settings\n",
    "CUSTOMERS_TO_PROCESS = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Qwen3 model... this may take a moment to download on first run.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\pfeil\\.cache\\huggingface\\hub\\models--Qwen--Qwen3-Embedding-0.6B. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 29\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Initialize the model immediately to ensure it downloads/loads correctly\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# before we start processing data.\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m embedding_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_local_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel loaded successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 13\u001b[0m, in \u001b[0;36mload_local_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading Qwen3 model... this may take a moment to download on first run.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# We load the model exactly as described in the instructions.\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# 'trust_remote_code=True' is often needed for newer/custom architectures like Qwen.\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mQwen/Qwen3-Embedding-0.6B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattn_implementation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mflash_attention_2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdevice_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpadding_side\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:327\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[1;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001b[0m\n\u001b[0;32m    309\u001b[0m has_modules \u001b[38;5;241m=\u001b[39m is_sentence_transformer_model(\n\u001b[0;32m    310\u001b[0m     model_name_or_path,\n\u001b[0;32m    311\u001b[0m     token,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    314\u001b[0m     local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    315\u001b[0m )\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    317\u001b[0m     has_modules\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_model_type(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    326\u001b[0m ):\n\u001b[1;32m--> 327\u001b[0m     modules, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_sbert_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    339\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_auto_model(\n\u001b[0;32m    340\u001b[0m         model_name_or_path,\n\u001b[0;32m    341\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    349\u001b[0m         has_modules\u001b[38;5;241m=\u001b[39mhas_modules,\n\u001b[0;32m    350\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:2305\u001b[0m, in \u001b[0;36mSentenceTransformer._load_sbert_model\u001b[1;34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code, local_files_only, model_kwargs, tokenizer_kwargs, config_kwargs)\u001b[0m\n\u001b[0;32m   2300\u001b[0m         module \u001b[38;5;241m=\u001b[39m module_class\u001b[38;5;241m.\u001b[39mload(local_path)\n\u001b[0;32m   2302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2303\u001b[0m     \u001b[38;5;66;03m# Newer modules that support the new loading method are loaded with the new style\u001b[39;00m\n\u001b[0;32m   2304\u001b[0m     \u001b[38;5;66;03m# i.e. with many keyword arguments that can optionally be used by the modules\u001b[39;00m\n\u001b[1;32m-> 2305\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mmodule_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2307\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Loading-specific keyword arguments\u001b[39;49;00m\n\u001b[0;32m   2308\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2313\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Module-specific keyword arguments\u001b[39;49;00m\n\u001b[0;32m   2314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2319\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2321\u001b[0m modules[module_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m module\n\u001b[0;32m   2322\u001b[0m module_kwargs[module_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m module_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n",
      "File \u001b[1;32mc:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\site-packages\\sentence_transformers\\models\\Transformer.py:365\u001b[0m, in \u001b[0;36mTransformer.load\u001b[1;34m(cls, model_name_or_path, subfolder, token, cache_folder, revision, local_files_only, trust_remote_code, model_kwargs, tokenizer_kwargs, config_kwargs, backend, **kwargs)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    351\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m    352\u001b[0m     init_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_load_init_kwargs(\n\u001b[0;32m    353\u001b[0m         model_name_or_path\u001b[38;5;241m=\u001b[39mmodel_name_or_path,\n\u001b[0;32m    354\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39msubfolder,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    363\u001b[0m         backend\u001b[38;5;241m=\u001b[39mbackend,\n\u001b[0;32m    364\u001b[0m     )\n\u001b[1;32m--> 365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(model_name_or_path\u001b[38;5;241m=\u001b[39mmodel_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minit_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\site-packages\\sentence_transformers\\models\\Transformer.py:88\u001b[0m, in \u001b[0;36mTransformer.__init__\u001b[1;34m(self, model_name_or_path, max_seq_length, model_args, tokenizer_args, config_args, cache_dir, do_lower_case, tokenizer_name_or_path, backend)\u001b[0m\n\u001b[0;32m     85\u001b[0m     config_args \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     87\u001b[0m config, is_peft_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_config(model_name_or_path, cache_dir, backend, config_args)\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_model(model_name_or_path, config, cache_dir, backend, is_peft_model, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_args)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# Get the signature of the auto_model's forward method to pass only the expected arguments from `features`,\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# plus some common values like \"input_ids\", \"attention_mask\", etc.\u001b[39;00m\n\u001b[0;32m     92\u001b[0m model_forward_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_model\u001b[38;5;241m.\u001b[39mforward)\u001b[38;5;241m.\u001b[39mparameters)\n",
      "File \u001b[1;32mc:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\site-packages\\sentence_transformers\\models\\Transformer.py:196\u001b[0m, in \u001b[0;36mTransformer._load_model\u001b[1;34m(self, model_name_or_path, config, cache_dir, backend, is_peft_model, **model_args)\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_mt5_model(model_name_or_path, config, cache_dir, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_args)\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_model \u001b[38;5;241m=\u001b[39m AutoModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    197\u001b[0m             model_name_or_path, config\u001b[38;5;241m=\u001b[39mconfig, cache_dir\u001b[38;5;241m=\u001b[39mcache_dir, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_args\n\u001b[0;32m    198\u001b[0m         )\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m backend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monnx\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_model \u001b[38;5;241m=\u001b[39m load_onnx_model(\n\u001b[0;32m    201\u001b[0m         model_name_or_path\u001b[38;5;241m=\u001b[39mmodel_name_or_path,\n\u001b[0;32m    202\u001b[0m         config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m    203\u001b[0m         task_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature-extraction\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    204\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_args,\n\u001b[0;32m    205\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:604\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    602\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mconfig_class \u001b[38;5;241m==\u001b[39m config\u001b[38;5;241m.\u001b[39msub_configs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    603\u001b[0m         config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_text_config()\n\u001b[1;32m--> 604\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    605\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    606\u001b[0m     )\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    609\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    610\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\site-packages\\transformers\\modeling_utils.py:277\u001b[0m, in \u001b[0;36mrestore_default_dtype.<locals>._wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    279\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[1;32mc:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\site-packages\\transformers\\modeling_utils.py:4806\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   4804\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeepSpeed Zero-3 is not compatible with passing a `device_map`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[1;32m-> 4806\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   4807\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4808\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires `accelerate`. You can install it with `pip install accelerate`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4809\u001b[0m         )\n\u001b[0;32m   4811\u001b[0m \u001b[38;5;66;03m# handling bnb config from kwargs, remove after `load_in_{4/8}bit` deprecation.\u001b[39;00m\n\u001b[0;32m   4812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_in_4bit \u001b[38;5;129;01mor\u001b[39;00m load_in_8bit:\n",
      "\u001b[1;31mValueError\u001b[0m: Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Model Initialization\n",
    "# ==============================================================================\n",
    "\n",
    "def load_local_model():\n",
    "    \"\"\"\n",
    "    Loads the Qwen3-Embedding-0.6B model from Hugging Face.\n",
    "    \"\"\"\n",
    "    print(\"Loading Qwen3 model... this may take a moment to download on first run.\")\n",
    "    \n",
    "    # We load the model exactly as described in the instructions.\n",
    "    # 'trust_remote_code=True' is often needed for newer/custom architectures like Qwen.\n",
    "    model = SentenceTransformer(\n",
    "        \"Qwen/Qwen3-Embedding-0.6B\",\n",
    "        trust_remote_code=True,\n",
    "        tokenizer_kwargs={\n",
    "            \"padding_side\": \"left\"\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Initialize the model immediately to ensure it downloads/loads correctly\n",
    "# before we start processing data.\n",
    "embedding_model = load_local_model()\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800115fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Helpers\n",
    "# ==============================================================================\n",
    "\n",
    "def atomic_pickle(obj, path: str):\n",
    "    \"\"\"\n",
    "    Saves data to a temporary file first, then renames it.\n",
    "    This prevents file corruption if the script crashes while saving.\n",
    "    \"\"\"\n",
    "    tmp = path + \".tmp\"\n",
    "    with open(tmp, \"wb\") as f:\n",
    "        pickle.dump(obj, f)\n",
    "    os.replace(tmp, path)\n",
    "\n",
    "def load_input() -> List[List[str]]:\n",
    "    \"\"\"Loads the raw customer transcript data.\"\"\"\n",
    "    with open(INPUT_PKL, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def load_existing() -> List[Dict[str, Any]]:\n",
    "    \"\"\"Loads data we have already processed to allow resuming.\"\"\"\n",
    "    if not os.path.exists(OUTPUT_PKL):\n",
    "        return []\n",
    "    with open(OUTPUT_PKL, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def embed_transcripts(model, transcripts: List[str]) -> List[List[float]]:\n",
    "    \"\"\"\n",
    "    Embeds a list of transcripts (documents) using the local Qwen model.\n",
    "    Returns a list of vectors (embeddings).\n",
    "    \"\"\"\n",
    "    # According to instructions, we treat these as documents.\n",
    "    # We do NOT use prompt_name=\"query\" because these are the texts to be stored, not the questions.\n",
    "    \n",
    "    # model.encode returns a numpy array or tensor. \n",
    "    # We convert it to a standard Python list using .tolist() for storage compatibility.\n",
    "    embeddings = model.encode(transcripts)\n",
    "    \n",
    "    return embeddings.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a35dea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Main Execution\n",
    "# ==============================================================================\n",
    "def main():\n",
    "    # 1. Load input data\n",
    "    try:\n",
    "        customer_data = load_input()\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Could not find '{INPUT_PKL}'. Make sure the file exists.\")\n",
    "    print(f\"Loaded {len(customer_data)} customer records from '{INPUT_PKL}'.\")\n",
    "\n",
    "    # 2. Resume support: load existing output and find which IDs are done\n",
    "    processed = load_existing()\n",
    "    done_ids = {rec[\"customer_id\"] for rec in processed}\n",
    "    \n",
    "    # Determine how many we still need to do\n",
    "    total = min(CUSTOMERS_TO_PROCESS, len(customer_data))\n",
    "    print(f\"Starting processing for {total} customers. Already done: {len(done_ids)}\")\n",
    "\n",
    "    # 3. Loop through customers\n",
    "    for i, transcripts in enumerate(customer_data[:total]):\n",
    "        # Skip if we already did this customer\n",
    "        if i in done_ids:\n",
    "            # Only print every 10th skipped to avoid clogging screen\n",
    "            if i % 10 == 0: \n",
    "                print(f\"Skipping customer {i} (already processed)\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # NEW: We pass the whole list of transcripts (usually 4) to the model at once.\n",
    "            # The model variable 'embedding_model' comes from Section 2.\n",
    "            embs = embed_transcripts(embedding_model, transcripts)\n",
    "\n",
    "            # Create the record\n",
    "            rec = {\n",
    "                \"customer_id\": i, \n",
    "                \"transcripts\": transcripts, \n",
    "                \"embeddings\": embs\n",
    "            }\n",
    "            processed.append(rec)\n",
    "\n",
    "            # Save immediately (atomic)\n",
    "            atomic_pickle(processed, OUTPUT_PKL)\n",
    "            \n",
    "            # Simple progress print\n",
    "            print(f\"Processed customer {i+1}/{total}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error on customer {i+1}: {e}\")\n",
    "            break\n",
    "\n",
    "    print(f\"\\nDone. Saved {len(processed)} customers to '{OUTPUT_PKL}'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9437247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Check file contents / Validation\n",
    "# ==============================================================================\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# We read the file we just created\n",
    "INPUT_PKL_CHECK = \"transcript_embeddings.pkl\"\n",
    "\n",
    "def load_pickle(path: str) -> List[Dict[str, Any]]:\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def cosine_matrix(X: np.ndarray) -> np.ndarray:\n",
    "    # Calculates similarity between all vectors in X against each other\n",
    "    norms = np.linalg.norm(X, axis=1, keepdims=True) + 1e-12\n",
    "    Xn = X / norms\n",
    "    return Xn @ Xn.T \n",
    "\n",
    "def main_check():\n",
    "    if not os.path.exists(INPUT_PKL_CHECK):\n",
    "        print(f\"File {INPUT_PKL_CHECK} not found. Run the previous cells first.\")\n",
    "        return\n",
    "\n",
    "    data = load_pickle(INPUT_PKL_CHECK)\n",
    "    n_customers = len(data)\n",
    "    print(f\"Loaded {n_customers} customer records from '{INPUT_PKL_CHECK}'.\")\n",
    "\n",
    "    # Storage for stats\n",
    "    bad_struct = []\n",
    "    dims = []\n",
    "    norms = []\n",
    "    lens_chars = []\n",
    "\n",
    "    for rec_idx, rec in enumerate(data):\n",
    "        if not isinstance(rec, dict):\n",
    "            bad_struct.append((rec_idx, \"record not dict\"))\n",
    "            continue\n",
    "\n",
    "        cid = rec.get(\"customer_id\")\n",
    "        transcripts = rec.get(\"transcripts\")\n",
    "        embeddings = rec.get(\"embeddings\")\n",
    "\n",
    "        # Basic validation: We expect 4 transcripts per customer\n",
    "        if not isinstance(transcripts, list) or len(transcripts) != 4:\n",
    "            bad_struct.append((cid, \"transcripts != 4\"))\n",
    "        if not isinstance(embeddings, list) or len(embeddings) != 4:\n",
    "            bad_struct.append((cid, \"embeddings != 4\"))\n",
    "\n",
    "        # Collect Length Stats\n",
    "        for t in (transcripts or []):\n",
    "            if isinstance(t, str):\n",
    "                lens_chars.append(len(t))\n",
    "\n",
    "        # Collect Embedding Stats\n",
    "        for v in (embeddings or []):\n",
    "            if isinstance(v, (list, tuple, np.ndarray)):\n",
    "                dims.append(len(v))\n",
    "                norms.append(float(np.linalg.norm(np.asarray(v, dtype=np.float32))))\n",
    "\n",
    "    if bad_struct:\n",
    "        print(f\"Found {len(bad_struct)} structural issues: {bad_struct[:5]}\")\n",
    "    else:\n",
    "        print(\"All records have 4 transcripts and 4 embeddings.\")\n",
    "\n",
    "    if dims:\n",
    "        unique_dims = sorted(set(dims))\n",
    "        # Explanation: Qwen3-0.6B usually has 1024 dimensions.\n",
    "        print(f\"Embedding dimension(s) found: {unique_dims} (Qwen3-0.6B usually returns 1024)\")\n",
    "        \n",
    "    if norms:\n",
    "        print(f\"Embedding L2-norm â€” mean: {statistics.mean(norms):.3f}, min: {min(norms):.3f}\")\n",
    "\n",
    "    # Show one example\n",
    "    if n_customers:\n",
    "        print(\"\\n--- Sample Record Check ---\")\n",
    "        r0 = data[0]\n",
    "        print(f\"Customer ID: {r0['customer_id']}\")\n",
    "        print(f\"Number of embeddings: {len(r0['embeddings'])}\")\n",
    "        print(f\"First embedding dimension: {len(r0['embeddings'][0])}\")\n",
    "        \n",
    "        # Calculate similarity for the first customer to ensure vectors aren't all zeros\n",
    "        E = np.array(r0[\"embeddings\"], dtype=np.float32)\n",
    "        print(\"\\nCosine Similarity Matrix for Customer 0:\")\n",
    "        print(cosine_matrix(E))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_check()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
