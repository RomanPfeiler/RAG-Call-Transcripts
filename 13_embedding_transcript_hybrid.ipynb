{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "190e9335",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pfeil\\anaconda3\\envs\\local-rag\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Imports\n",
    "# ==============================================================================\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. For Dense Embedding (The \"Meaning\" Search)\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 2. For Sparse Embedding (The \"Keyword\" Search)\n",
    "# Note: We only need the tokenizer logic here, but we import the library to ensure it's installed.\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# ==============================================================================\n",
    "# Config\n",
    "# ==============================================================================\n",
    "INPUT_PKL  = \"repackaged_transcript_data.pkl\"\n",
    "OUTPUT_PKL = \"transcript_embeddings_hybrid.pkl\"\n",
    "\n",
    "CUSTOMERS_TO_PROCESS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b452042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Initialize Dense Model (Qwen)\n",
    "# ==============================================================================\n",
    "print(\"Loading Qwen3 model... (Dense Embeddings)\")\n",
    "\n",
    "embedding_model = SentenceTransformer(\n",
    "    \"Qwen/Qwen3-Embedding-0.6B\",\n",
    "    trust_remote_code=True,\n",
    "    tokenizer_kwargs={\"padding_side\": \"left\"}\n",
    ")\n",
    "\n",
    "print(\"Qwen model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a801744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Helpers\n",
    "# ==============================================================================\n",
    "\n",
    "def atomic_pickle(obj, path: str):\n",
    "    \"\"\"Saves data safely.\"\"\"\n",
    "    tmp = path + \".tmp\"\n",
    "    with open(tmp, \"wb\") as f:\n",
    "        pickle.dump(obj, f)\n",
    "    os.replace(tmp, path)\n",
    "\n",
    "def load_input() -> List[List[str]]:\n",
    "    with open(INPUT_PKL, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def load_existing() -> List[Dict[str, Any]]:\n",
    "    if not os.path.exists(OUTPUT_PKL):\n",
    "        return []\n",
    "    with open(OUTPUT_PKL, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# --- Dense Logic (Qwen) ---\n",
    "def embed_transcripts_dense(model, transcripts: List[str]) -> List[List[float]]:\n",
    "    \"\"\"Generates the vector embeddings.\"\"\"\n",
    "    embeddings = model.encode(transcripts)\n",
    "    return embeddings.tolist()\n",
    "\n",
    "# --- Sparse Logic (BM25) ---\n",
    "def tokenize_text(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Splits text into tokens for BM25.\n",
    "    Logic: Lowercase -> Remove special chars -> Split by space.\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', ' ', text)\n",
    "    tokens = [t for t in text.split(\" \") if t.strip()]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763973d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Main Hybrid Generation\n",
    "# ==============================================================================\n",
    "def main():\n",
    "    # 1. Load Data\n",
    "    try:\n",
    "        customer_data = load_input()\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Could not find '{INPUT_PKL}'.\")\n",
    "    \n",
    "    # 2. Resume Logic\n",
    "    processed = load_existing()\n",
    "    done_ids = {rec[\"customer_id\"] for rec in processed}\n",
    "    total = min(CUSTOMERS_TO_PROCESS, len(customer_data))\n",
    "    \n",
    "    print(f\"Starting HYBRID processing for {total} customers...\")\n",
    "\n",
    "    for i, transcripts in enumerate(customer_data[:total]):\n",
    "        if i in done_ids:\n",
    "            if (i+1) % 10 == 0: print(f\"Skipping {i+1} (Done)\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # --- A. Generate Dense Embeddings (Qwen) ---\n",
    "            # Result: List of Lists of Floats (e.g. [[0.1, 0.5...], ...])\n",
    "            dense_vectors = embed_transcripts_dense(embedding_model, transcripts)\n",
    "\n",
    "            # --- B. Generate Sparse Tokens (BM25) ---\n",
    "            # Result: List of Lists of Strings (e.g. [['hello', 'world'], ...])\n",
    "            sparse_tokens = [tokenize_text(t) for t in transcripts]\n",
    "\n",
    "            # --- C. Create Hybrid Record ---\n",
    "            rec = {\n",
    "                \"customer_id\": i,\n",
    "                \"transcripts\": transcripts,      # Raw Text (for reading)\n",
    "                \"dense_embeddings\": dense_vectors, # For Semantic Search\n",
    "                \"bm25_tokens\": sparse_tokens     # For Keyword Search\n",
    "            }\n",
    "            \n",
    "            processed.append(rec)\n",
    "            atomic_pickle(processed, OUTPUT_PKL)\n",
    "            \n",
    "            print(f\"Processed customer {i+1}/{total}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error on customer {i+1}: {e}\")\n",
    "            break\n",
    "\n",
    "    print(f\"\\nDone. Hybrid data saved to '{OUTPUT_PKL}'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f402fe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Check file contents / Validation\n",
    "# ==============================================================================\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "FILE_TO_CHECK = \"transcript_embeddings_hybrid.pkl\"\n",
    "\n",
    "def main_check():\n",
    "    if not os.path.exists(FILE_TO_CHECK):\n",
    "        print(\"File not found.\")\n",
    "        return\n",
    "\n",
    "    data = pickle.load(open(FILE_TO_CHECK, \"rb\"))\n",
    "    print(f\"Loaded {len(data)} records.\")\n",
    "\n",
    "    if len(data) == 0:\n",
    "        return\n",
    "\n",
    "    # Check the first record\n",
    "    rec = data[0]\n",
    "    print(\"\\n--- Hybrid Record Structure Check ---\")\n",
    "    print(f\"Keys found: {list(rec.keys())}\")\n",
    "    \n",
    "    # Check Dense\n",
    "    dense = rec.get(\"dense_embeddings\", [])\n",
    "    if dense:\n",
    "        dims = len(dense[0])\n",
    "        print(f\"\\n[Dense] Embeddings present? Yes.\")\n",
    "        print(f\"[Dense] Count: {len(dense)}\")\n",
    "        print(f\"[Dense] Dimensions: {dims} (Expected ~1024 for Qwen)\")\n",
    "    else:\n",
    "        print(\"\\n[Dense] MISSING!\")\n",
    "\n",
    "    # Check Sparse\n",
    "    sparse = rec.get(\"bm25_tokens\", [])\n",
    "    if sparse:\n",
    "        print(f\"\\n[Sparse] Tokens present? Yes.\")\n",
    "        print(f\"[Sparse] Count: {len(sparse)}\")\n",
    "        print(f\"[Sparse] First 5 tokens of transcript 0: {sparse[0][:5]}\")\n",
    "    else:\n",
    "        print(\"\\n[Sparse] MISSING!\")\n",
    "\n",
    "    print(\"\\nStatus: Ready for Hybrid RAG.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_check()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
