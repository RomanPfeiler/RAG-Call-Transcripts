{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42c8234f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded. Ready to perform Keyword Search (BM25).\n"
     ]
    }
   ],
   "source": [
    "# ============================== Setup & imports ==============================\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import re # For text cleaning\n",
    "import time\n",
    "from typing import List, Dict, Any, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# NEW: The library for keyword scoring\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# Filter warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ============================== CONFIGURATION ==============================\n",
    "\n",
    "# 1. Customer data input\n",
    "# This now points to the file containing LISTS OF TOKENS, not vectors.\n",
    "CUSTOMER_PKL = \"transcript_data_bm25_ready.pkl\"\n",
    "\n",
    "# 2. Evaluation Data (Same as before)\n",
    "EVAL_DIR = \"Evaluation-data\"\n",
    "PROMPT_FILES = [\n",
    "    \"automotive_prompts.jsonl\",\n",
    "    \"home_service_prompts.jsonl\",\n",
    "    \"insurance_prompts.jsonl\",\n",
    "    \"medical_equipment_prompts.jsonl\",\n",
    "]\n",
    "\n",
    "# 3. Categories (Same mapping)\n",
    "CATEGORIES = [\n",
    "    \"automotive - inbound call\",\n",
    "    \"home service - inbound call\",\n",
    "    \"insurance - outbound call\",\n",
    "    \"medical equipment - outbound call\",\n",
    "]\n",
    "INDEX_TO_CATEGORY = dict(enumerate(CATEGORIES))\n",
    "CATEGORY_TO_INDEX = {c: i for i, c in INDEX_TO_CATEGORY.items()}\n",
    "\n",
    "print(\"Configuration loaded. Ready to perform Keyword Search (BM25).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29d8dd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Hello! This is an AUTO-motive call...\n",
      "Tokenized: ['hello', 'this', 'is', 'an', 'auto', 'motive', 'call']\n"
     ]
    }
   ],
   "source": [
    "# ============================== TEXT PROCESSING UTILS ==============================\n",
    "\n",
    "def simple_tokenize(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Splits text into words (tokens) for BM25.\n",
    "    Must match the logic used to create the transcript pickle file!\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    \n",
    "    # 1. Lowercase\n",
    "    text = text.lower()\n",
    "    # 2. Remove punctuation (replace with space)\n",
    "    text = re.sub(r'[^a-z0-9\\s]', ' ', text)\n",
    "    # 3. Split by whitespace and remove empty strings\n",
    "    tokens = [t for t in text.split(\" \") if t.strip()]\n",
    "    return tokens\n",
    "\n",
    "# Quick test to make sure it works\n",
    "sample_text = \"Hello! This is an AUTO-motive call...\"\n",
    "print(f\"Original: {sample_text}\")\n",
    "print(f\"Tokenized: {simple_tokenize(sample_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a11c718c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50 customers.\n",
      "Loaded 80 prompts.\n",
      "Tokenizing prompts...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# ============================== LOAD DATA ==============================\n",
    "\n",
    "# 1. Load Customer Transcripts\n",
    "if not os.path.exists(CUSTOMER_PKL):\n",
    "    raise FileNotFoundError(f\"File '{CUSTOMER_PKL}' not found.\")\n",
    "\n",
    "with open(CUSTOMER_PKL, \"rb\") as f:\n",
    "    customer_records: List[Dict[str, Any]] = pickle.load(f)\n",
    "\n",
    "# Validation check\n",
    "rec0 = customer_records[0]\n",
    "assert \"bm25_tokens\" in rec0, \"Data file is missing 'bm25_tokens'. Did you run the right preprocessing script?\"\n",
    "print(f\"Loaded {len(customer_records)} customers.\")\n",
    "\n",
    "# 2. Load Prompts\n",
    "def load_jsonl(path: str) -> List[Dict[str, Any]]:\n",
    "    items = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if line.strip(): items.append(json.loads(line))\n",
    "    return items\n",
    "\n",
    "all_prompts: List[Dict[str, Any]] = []\n",
    "for fname in PROMPT_FILES:\n",
    "    p = os.path.join(EVAL_DIR, fname)\n",
    "    if os.path.exists(p):\n",
    "        all_prompts.extend(load_jsonl(p))\n",
    "\n",
    "print(f\"Loaded {len(all_prompts)} prompts.\")\n",
    "\n",
    "# Prepare prompt lists\n",
    "prompt_texts = [p[\"prompt\"] for p in all_prompts]\n",
    "prompt_ids   = [p[\"id\"] for p in all_prompts]\n",
    "prompt_cats  = [p[\"category\"] for p in all_prompts]\n",
    "prompt_diffs = [p[\"difficulty\"] for p in all_prompts]\n",
    "\n",
    "# PRE-TOKENIZE PROMPTS\n",
    "# Since BM25 is fast, we can tokenize all prompts now to save time in the loop.\n",
    "print(\"Tokenizing prompts...\")\n",
    "prompt_tokens_list = [simple_tokenize(t) for t in prompt_texts]\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5485aae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================== METRICS UTILS ==============================\n",
    "\n",
    "def softmax(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Stable softmax to convert BM25 scores into probabilities.\"\"\"\n",
    "    x = np.asarray(x, dtype=np.float32)\n",
    "    # subtracting max prevents overflow for large BM25 scores\n",
    "    x = x - np.max(x) \n",
    "    e = np.exp(x)\n",
    "    return e / (np.sum(e) + 1e-12)\n",
    "\n",
    "def loss_metrics(scores: np.ndarray, correct_idx: int) -> dict:\n",
    "    \"\"\"\n",
    "    Calculates metrics based on the 4 scores.\n",
    "    \"\"\"\n",
    "    probs = softmax(scores)\n",
    "    \n",
    "    # 1. Cross Entropy (how confident were we in the right answer?)\n",
    "    cross_entropy = -np.log(probs[correct_idx] + 1e-12)\n",
    "\n",
    "    # 2. Margin (Difference between Correct Score and the Best Wrong Score)\n",
    "    correct_score = float(scores[correct_idx])\n",
    "    best_other_score = float(np.max(np.delete(scores, correct_idx)))\n",
    "    signed_margin = correct_score - best_other_score \n",
    "\n",
    "    # 3. Rank\n",
    "    order = np.argsort(-scores) # Sort descending\n",
    "    rank_of_correct = int(np.where(order == correct_idx)[0][0]) + 1 \n",
    "\n",
    "    return {\n",
    "        \"cross_entropy\": float(cross_entropy),\n",
    "        \"signed_margin\": float(signed_margin),\n",
    "        \"correct_score\": correct_score,\n",
    "        \"best_other_score\": best_other_score,\n",
    "        \"rank_of_correct\": rank_of_correct,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2c5c8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation...\n",
      "Evaluated 10/50 customers...\n",
      "Evaluated 20/50 customers...\n",
      "Evaluated 30/50 customers...\n",
      "Evaluated 40/50 customers...\n",
      "Evaluated 50/50 customers...\n",
      "Total evaluations: 4000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_row</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_category</th>\n",
       "      <th>prompt_difficulty</th>\n",
       "      <th>predicted_category</th>\n",
       "      <th>is_correct</th>\n",
       "      <th>top_index</th>\n",
       "      <th>top_score</th>\n",
       "      <th>cross_entropy</th>\n",
       "      <th>signed_margin</th>\n",
       "      <th>correct_score</th>\n",
       "      <th>best_other_score</th>\n",
       "      <th>rank_of_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>auto-e-01</td>\n",
       "      <td>automotive - inbound call</td>\n",
       "      <td>easy</td>\n",
       "      <td>home service - inbound call</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.519128</td>\n",
       "      <td>2.366547</td>\n",
       "      <td>-1.864948</td>\n",
       "      <td>0.654180</td>\n",
       "      <td>2.519128</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>auto-e-02</td>\n",
       "      <td>automotive - inbound call</td>\n",
       "      <td>easy</td>\n",
       "      <td>medical equipment - outbound call</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.767087</td>\n",
       "      <td>2.074630</td>\n",
       "      <td>-1.200462</td>\n",
       "      <td>0.566625</td>\n",
       "      <td>1.767087</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>auto-e-03</td>\n",
       "      <td>automotive - inbound call</td>\n",
       "      <td>easy</td>\n",
       "      <td>medical equipment - outbound call</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.735542</td>\n",
       "      <td>2.006757</td>\n",
       "      <td>-1.096479</td>\n",
       "      <td>0.639063</td>\n",
       "      <td>1.735542</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>auto-e-04</td>\n",
       "      <td>automotive - inbound call</td>\n",
       "      <td>easy</td>\n",
       "      <td>home service - inbound call</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.451721</td>\n",
       "      <td>1.748309</td>\n",
       "      <td>-0.975393</td>\n",
       "      <td>0.476329</td>\n",
       "      <td>1.451721</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>auto-e-05</td>\n",
       "      <td>automotive - inbound call</td>\n",
       "      <td>easy</td>\n",
       "      <td>home service - inbound call</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.488464</td>\n",
       "      <td>2.304553</td>\n",
       "      <td>-1.674260</td>\n",
       "      <td>0.814204</td>\n",
       "      <td>2.488464</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_row  customer_id  prompt_id            prompt_category  \\\n",
       "0             1            0  auto-e-01  automotive - inbound call   \n",
       "1             1            0  auto-e-02  automotive - inbound call   \n",
       "2             1            0  auto-e-03  automotive - inbound call   \n",
       "3             1            0  auto-e-04  automotive - inbound call   \n",
       "4             1            0  auto-e-05  automotive - inbound call   \n",
       "\n",
       "  prompt_difficulty                 predicted_category  is_correct  top_index  \\\n",
       "0              easy        home service - inbound call           0          1   \n",
       "1              easy  medical equipment - outbound call           0          3   \n",
       "2              easy  medical equipment - outbound call           0          3   \n",
       "3              easy        home service - inbound call           0          1   \n",
       "4              easy        home service - inbound call           0          1   \n",
       "\n",
       "   top_score  cross_entropy  signed_margin  correct_score  best_other_score  \\\n",
       "0   2.519128       2.366547      -1.864948       0.654180          2.519128   \n",
       "1   1.767087       2.074630      -1.200462       0.566625          1.767087   \n",
       "2   1.735542       2.006757      -1.096479       0.639063          1.735542   \n",
       "3   1.451721       1.748309      -0.975393       0.476329          1.451721   \n",
       "4   2.488464       2.304553      -1.674260       0.814204          2.488464   \n",
       "\n",
       "   rank_of_correct  \n",
       "0                3  \n",
       "1                3  \n",
       "2                4  \n",
       "3                4  \n",
       "4                4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================== EVALUATION LOOP ==============================\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"Starting evaluation...\")\n",
    "\n",
    "for c_idx, rec in enumerate(customer_records, start=1):\n",
    "    \n",
    "    # 1. Get the corpus for this specific customer\n",
    "    # This is a list of 4 lists of tokens: [[tokens_doc1], [tokens_doc2], ...]\n",
    "    corpus_tokens = rec[\"bm25_tokens\"]\n",
    "    \n",
    "    # 2. Initialize BM25 for this customer\n",
    "    # This acts as our \"Search Engine\" for this specific customer record\n",
    "    bm25 = BM25Okapi(corpus_tokens)\n",
    "\n",
    "    # 3. Loop through all prompts\n",
    "    for p_idx, (pid, pcat, pdiff) in enumerate(zip(prompt_ids, prompt_cats, prompt_diffs)):\n",
    "        \n",
    "        # Get the pre-tokenized prompt\n",
    "        q_tokens = prompt_tokens_list[p_idx]\n",
    "\n",
    "        # 4. Get BM25 Scores\n",
    "        # This returns a list of 4 float scores (one for each transcript)\n",
    "        scores_list = bm25.get_scores(q_tokens)\n",
    "        scores = np.array(scores_list, dtype=np.float32)\n",
    "\n",
    "        # 5. Determine Winner\n",
    "        top_idx = int(np.argmax(scores))\n",
    "\n",
    "        # 6. Calculate Metrics (Same as before)\n",
    "        correct_idx = CATEGORY_TO_INDEX[pcat]\n",
    "        metrics = loss_metrics(scores, correct_idx)\n",
    "\n",
    "        pred_category = INDEX_TO_CATEGORY[top_idx]\n",
    "        is_correct = int(pred_category == pcat)\n",
    "\n",
    "        row = {\n",
    "            \"customer_row\": c_idx,\n",
    "            \"customer_id\": rec.get(\"customer_id\", None),\n",
    "            \"prompt_id\": pid,\n",
    "            \"prompt_category\": pcat,\n",
    "            \"prompt_difficulty\": pdiff,\n",
    "            \"predicted_category\": pred_category,\n",
    "            \"is_correct\": is_correct,\n",
    "            \"top_index\": top_idx,\n",
    "            \"top_score\": float(scores[top_idx]),\n",
    "            **metrics,\n",
    "        }\n",
    "        results.append(row)\n",
    "    \n",
    "    # Progress check\n",
    "    if c_idx % 10 == 0:\n",
    "        print(f\"Evaluated {c_idx}/{len(customer_records)} customers...\")\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(f\"Total evaluations: {len(df)}\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3caad052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Accuracy by Category × Difficulty (BM25) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_category</th>\n",
       "      <th>prompt_difficulty</th>\n",
       "      <th>accuracy_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>automotive - inbound call</td>\n",
       "      <td>easy</td>\n",
       "      <td>44.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>automotive - inbound call</td>\n",
       "      <td>hard</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>home service - inbound call</td>\n",
       "      <td>easy</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>home service - inbound call</td>\n",
       "      <td>hard</td>\n",
       "      <td>41.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insurance - outbound call</td>\n",
       "      <td>easy</td>\n",
       "      <td>41.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>insurance - outbound call</td>\n",
       "      <td>hard</td>\n",
       "      <td>28.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>medical equipment - outbound call</td>\n",
       "      <td>easy</td>\n",
       "      <td>36.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>medical equipment - outbound call</td>\n",
       "      <td>hard</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     prompt_category prompt_difficulty  accuracy_pct\n",
       "0          automotive - inbound call              easy          44.8\n",
       "1          automotive - inbound call              hard          35.0\n",
       "2        home service - inbound call              easy          54.0\n",
       "3        home service - inbound call              hard          41.2\n",
       "4          insurance - outbound call              easy          41.4\n",
       "5          insurance - outbound call              hard          28.6\n",
       "6  medical equipment - outbound call              easy          36.4\n",
       "7  medical equipment - outbound call              hard          26.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Overall Accuracy ===\n",
      "38.42%\n",
      "\n",
      "=== Loss Metrics ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall_accuracy_pct</th>\n",
       "      <th>mean_cross_entropy</th>\n",
       "      <th>mean_signed_margin</th>\n",
       "      <th>mean_deficit_if_wrong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38.425</td>\n",
       "      <td>1.422146</td>\n",
       "      <td>-0.309185</td>\n",
       "      <td>1.231413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall_accuracy_pct  mean_cross_entropy  mean_signed_margin  \\\n",
       "0                38.425            1.422146           -0.309185   \n",
       "\n",
       "   mean_deficit_if_wrong  \n",
       "0               1.231413  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================== METRICS & TABLES ==============================\n",
    "\n",
    "if len(df) > 0:\n",
    "    def pct(x: pd.Series) -> float:\n",
    "        return 100.0 * x.mean()\n",
    "\n",
    "    # Accuracy by category × difficulty\n",
    "    pivot_cat_diff = (\n",
    "        df\n",
    "        .groupby([\"prompt_category\", \"prompt_difficulty\"])[\"is_correct\"]\n",
    "        .apply(pct)\n",
    "        .rename(\"accuracy_pct\")\n",
    "        .reset_index()\n",
    "        .sort_values([\"prompt_category\", \"prompt_difficulty\"])\n",
    "    )\n",
    "\n",
    "    overall_accuracy_pct = pct(df[\"is_correct\"])\n",
    "\n",
    "    print(\"=== Accuracy by Category × Difficulty (BM25) ===\")\n",
    "    display(pivot_cat_diff)\n",
    "\n",
    "    print(f\"\\n=== Overall Accuracy ===\\n{overall_accuracy_pct:.2f}%\")\n",
    "\n",
    "    # Loss Metrics\n",
    "    # Note: 'deficit' here means difference in BM25 score points\n",
    "    df[\"deficit_if_wrong\"] = np.where(\n",
    "        df[\"is_correct\"] == 0,\n",
    "        df[\"best_other_score\"] - df[\"correct_score\"],\n",
    "        0.0\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== Loss Metrics ===\")\n",
    "    overall_stats = pd.DataFrame({\n",
    "        \"overall_accuracy_pct\": [overall_accuracy_pct],\n",
    "        \"mean_cross_entropy\":   [df[\"cross_entropy\"].mean()],\n",
    "        \"mean_signed_margin\":   [df[\"signed_margin\"].mean()], \n",
    "        \"mean_deficit_if_wrong\":[df.loc[df[\"is_correct\"]==0, \"deficit_if_wrong\"].mean()]\n",
    "    })\n",
    "    display(overall_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146b832a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
