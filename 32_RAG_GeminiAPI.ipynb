{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68e9d52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with Kernel: gemini-chat-env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d61d45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Install & imports ====\n",
    "\n",
    "import pickle\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# Gemini\n",
    "from google import genai\n",
    "from google.genai import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65382291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Configure paths and models ==== \n",
    "\n",
    "# Embedding model used for your stored vectors (3072-D by default).\n",
    "EMBED_MODEL = \"gemini-embedding-001\"\n",
    "\n",
    "# Chat model to answer with context from the best transcript.\n",
    "CHAT_MODEL = \"gemini-2.0-flash-lite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c36949cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_key_from_env_file(filename: str = \"key.env\", var_name: str = \"GEMINI_API_KEY\") -> str:\n",
    "    p = Path.cwd() / filename  # current working directory (your notebook folder)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"'{filename}' not found in {Path.cwd()}\")\n",
    "    for line in p.read_text(encoding=\"utf-8\").splitlines():\n",
    "        line = line.strip()\n",
    "        if not line or line.startswith(\"#\"):\n",
    "            continue\n",
    "        if \"=\" in line:\n",
    "            k, v = line.split(\"=\", 1)\n",
    "            if k.strip() == var_name:\n",
    "                return v.strip().strip('\"').strip(\"'\")\n",
    "    raise RuntimeError(f\"{var_name} not found in {filename}\")\n",
    "\n",
    "API_KEY = read_key_from_env_file()\n",
    "\n",
    "# Create a single shared client for both embedding + chat.\n",
    "client = genai.Client(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "185953ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50 customer records from 'transcript_embeddings.pkl'.\n"
     ]
    }
   ],
   "source": [
    "# ==== Load data + Validation ====\n",
    "\n",
    "DATA_FILE = \"transcript_embeddings.pkl\"\n",
    "\n",
    "with open(DATA_FILE, \"rb\") as f:\n",
    "    records = pickle.load(f)\n",
    "\n",
    "print(f\"Loaded {len(records)} customer records from '{DATA_FILE}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "deb54f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Record selection helper ====\n",
    "\n",
    "def select_customer(records: List[Dict[str, Any]], selector: int) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Selects a single customer record.\n",
    "\n",
    "    Behavior:\n",
    "    - First try exact match on customer_id == selector.\n",
    "    - If not found, treat 'selector' as 1-based index into the list (1..len(records)).\n",
    "\n",
    "    Returns the chosen record (dict with 'customer_id', 'transcripts', 'embeddings').\n",
    "    \"\"\"\n",
    "    # Try customer_id match.\n",
    "    for rec in records:\n",
    "        if rec[\"customer_id\"] == selector:\n",
    "            return rec\n",
    "\n",
    "    # Fallback: 1-based position in the list.\n",
    "    idx = selector - 1\n",
    "    assert 0 <= idx < len(records), f\"Client index {selector} is out of range.\"\n",
    "    return records[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5357ed79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Embedding & ranking utilities ====\n",
    "\n",
    "# Normalization is not necesary with the Gemini embedding model.\n",
    "# However, it´s included to be robust in case of future changes to the model or different embedding models.\n",
    "def l2_normalize(vecs: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    L2-normalizes vectors row-wise. Safe even if some rows are already normalized.\n",
    "    vecs: shape (n, d) or (d,)\n",
    "    returns: same shape, L2-norm ~ 1.0 per row (or vector)\n",
    "    \"\"\"\n",
    "    vecs = np.asarray(vecs, dtype=np.float32)\n",
    "    if vecs.ndim == 1:\n",
    "        denom = np.linalg.norm(vecs) + 1e-12\n",
    "        return vecs / denom\n",
    "    denom = np.linalg.norm(vecs, axis=1, keepdims=True) + 1e-12\n",
    "    return vecs / denom\n",
    "\n",
    "\n",
    "def embed_prompt(prompt: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Embeds the user prompt using the same Gemini embedding model.\n",
    "    Returns a (3072,) float32 numpy array.\n",
    "    \"\"\"\n",
    "    # Request a single embedding for the prompt.\n",
    "    result = client.models.embed_content(\n",
    "        model=EMBED_MODEL,\n",
    "        contents=prompt,\n",
    "        # For RAG, RETRIEVAL_QUERY is a good default:\n",
    "        config=types.EmbedContentConfig(task_type=\"RETRIEVAL_QUERY\")\n",
    "    )\n",
    "    [embedding_obj] = result.embeddings\n",
    "    v = np.array(embedding_obj.values, dtype=np.float32)\n",
    "\n",
    "    # gemini-embedding-001 returns normalized vectors at 3072-D by default,\n",
    "    # but we normalize defensively to be robust if dimensions/settings change later.\n",
    "    return l2_normalize(v)\n",
    "\n",
    "\n",
    "def rank_transcripts_by_cosine(query_vec: np.ndarray,\n",
    "                               doc_vecs: np.ndarray) -> List[Tuple[int, float]]:\n",
    "    \"\"\"\n",
    "    Ranks 4 transcript vectors (doc_vecs shape (4, 3072)) by cosine similarity to query_vec.\n",
    "    Returns a list of (index, score) sorted descending by score.\n",
    "\n",
    "    Since vectors are L2-normalized, cosine similarity reduces to a simple dot product.\n",
    "    \"\"\"\n",
    "    q = l2_normalize(query_vec)\n",
    "    D = l2_normalize(doc_vecs)  # (4, 3072)\n",
    "\n",
    "    scores = (D @ q)  # (4,)\n",
    "    order = np.argsort(-scores)  # descending\n",
    "    return [(int(i), float(scores[i])) for i in order]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b4fc814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Printing utilities ====\n",
    "\n",
    "def print_ranked_transcripts(transcripts: List[str],\n",
    "                             ranking: List[Tuple[int, float]],\n",
    "                             show_full: bool = True,\n",
    "                             preview_chars: int = 400) -> None:\n",
    "    \"\"\"\n",
    "    Prints all 4 transcripts in similarity order with scores.\n",
    "    Set show_full=False to print a shorter preview per transcript.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 100)\n",
    "    print(\"Top 4 transcripts by cosine similarity\")\n",
    "    print(\"=\" * 100)\n",
    "    for rank, (idx, score) in enumerate(ranking, start=1):\n",
    "        print(f\"\\n[{rank}] Transcript #{idx+1} — cosine={score:.4f}\")\n",
    "        print(\"-\" * 100)\n",
    "        text = transcripts[idx]\n",
    "        if show_full:\n",
    "            print(text)\n",
    "        else:\n",
    "            print(text[:preview_chars] + (\"...\" if len(text) > preview_chars else \"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a8b58bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Top 4 transcripts by cosine similarity\n",
      "====================================================================================================\n",
      "\n",
      "[1] Transcript #2 — cosine=0.6494\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Hello? Yes, how can I help you? Yes, hi, is this the glass docr you over for [ORGANIZATION] in [LOCATION]? Yes, ma'am. Okay. Just wanted to make sure I had the right phone number because I just did a quick search. I didn't have my glasses on. I have my windshield replace there not too long ago. And the little bracket part that goes around the rearview mirror, you know it's one of those ones as like camera and stuff and you know for you know one of those fancy whatever windshield. And he said something about when I. When he did, he said the brackets were being troublesome but the [MEDICAL_CONDITION] pieces keeps. It keeps falling and it won't stay up anymore. And I was just curious if that's something that y'all could take a look at and see if there was something that needed to be fixed on it. Yeah, let me see. I hope I explained that well. Yeah, no, I get you. Okay. What is the phone number that you provided us with? There is one. My name is [PERSON_NAME] [PERSON_NAME]. Is it the 2016piloter migrant? Correct. All. Okay. Will you be able to come in tomorrow to our [LOCATION] shop so we can take a look? I can't. I'm going to be out of town this weekend but I could do pretty much any [DURATION] next [DURATION]. Okay, let me start getting you set one more time. That phone number, correct? That's my cell phone. And did Monday work for you at about [TIME]? Let me check. Hold on one second. Are you there? Yes, I'm here. Okay. Monday is a school holiday. Is there. You know, just happen to have an in service [DURATION] that [DURATION]. Would you happen to have anything on Tuesday and then that way that is not. I don't have to drag my son. Yeah, we actually have [DURATION] [DURATION] available anywhere from [TIME] to [TIME]. Which time works best for you? Let's aim for [TIME] on Tuesday. Would that work? That works great. Okay, well then I'll see at [TIME] on Tuesday. All right. You have a great weekend. Okay. Thank you. You too. Thank you. Byee.\n",
      "\n",
      "[2] Transcript #1 — cosine=0.6273\n",
      "----------------------------------------------------------------------------------------------------\n",
      "We are trying to contact your [OCCUPATION] [OCCUPATION] from [ORGANIZATION]. Hello, this is [PERSON_NAME] of [ORGANIZATION] [ORGANIZATION]. How can I help you? Hi, I was wondering if I have a notification on my app that my fuel pump has a recall. Oh, let's take a look. Okay. Let's start with your telephone number. [PHONE_NUMBER]. [PHONE_NUMBER]. All right. [PHONE_NUMBER] [PHONE_NUMBER]. Yes. Okay, I'm just hopping into my system now to look. Okay. Yeah, it's something, but it's not that. So it looks like for your vehicle. So usually when they release that recall notice, it's because some of your model year is affected by that, but it looks like there's no open recall for your vehicle. So it looks like your vehicle would not be affected by that. Okay, so my next question is my car will not start. So I don't know, is there like roadside assistance or anything for that? Yeah, I can give you roadside assistance number to have to. Because you have it for free. So they can tow it in here and then we could take a look at it. Oh, geez. They'd have to tow it. They couldn't just fix it here. What would. I mean, do you drive the vehicle often? Is it possible that the battery's dead? No, I just drove it. I drive it every day. Just drove it last night. And it's not making that clicking sound, so I don't think it's the battery. But this is the second time it's happened here, so. Which is weird. Okay, let me give you their number, and then if they can't help you out, give me a call back and we'll see if we can get you all fixed up. Okay, sounds good. What's the number? So it's going to be [PHONE_NUMBER], [PHONE_NUMBER]. Okay. [PHONE_NUMBER], [PHONE_NUMBER], [PHONE_NUMBER]. Okay. Do you not. Do you have the actual number or no? Yes. So that's going to be [PHONE_NUMBER]. I think there's a number missing. [PHONE_NUMBER]. I'm sorry. I'm sorry. Okay, there we go. Now there's enough numbers. All right. Okay. Hopefully they can fix it again. So I'll give you a call if they can. No problem. Bye. All right, bye.\n",
      "\n",
      "[3] Transcript #4 — cosine=0.6246\n",
      "----------------------------------------------------------------------------------------------------\n",
      "We will discuss. Hello? Hello? Yes, hello. Yes, hello, this is [PERSON_NAME] again. Am I speaking to [PERSON_NAME] [PERSON_NAME]? Yes. Okay, Mr. [PERSON_NAME], I forgot to tell you a while ago that you're going to receive the additional benefits for your insurance, my [ORGANIZATION] [ORGANIZATION]. Yes, sir. Yeah. Okay. And then I'm going to let you speak my [OCCUPATION] to explain to you about your additional benefits. Okay? Yeah. Okay, here she is now. Yes, hello. Thank you so much for holding. This is [PERSON_NAME] [PERSON_NAME] from [ORGANIZATION] [ORGANIZATION] and I'm one of the [OCCUPATION] here in [ORGANIZATION] [ORGANIZATION]. Okay. Yeah, yeah. So sir, I may ask. So whenever you visit your [OCCUPATION] or hospital, even in with your specialist, do you pay some money out of your pocket as a copay payments or sometimes like that? I don't pay no co payments. Okay, so what I'm going to do now is to fill up your online form here. [PERSON_NAME] [PERSON_NAME], right? Yeah. Okay. For you to qualify to receive this additional benefits. And your date of birth is [DATE_OF_BIRTH] [DATE_OF_BIRTH], right? Yes. Okay, so I have your full address. Your full address here is from [LOCATION] [LOCATION]. [LOCATION] [LOCATION], [LOCATION] [LOCATION], [LOCATION] [LOCATION], right? Yes. Okay, so you're from [LOCATION] [LOCATION] [LOCATION], right? Yeah. And your zip code is [LOCATION], correct? Yes. Okay, you're from the state of [LOCATION], correct? Yes. Okay, I have your Medicare ID number here. So what I'm going to do now, sir, is to transfer you over to our current [OCCUPATION]. They're just going to verify all the information that I have here, and they're going to provide your additional benefits here now. Okay. Okay, here we go. Stand online. We're connecting now. Stand the line. Okay, thanks for holding. This is [PERSON_NAME]. I am a [OCCUPATION] [OCCUPATION]. Yes, I have [PERSON_NAME] [PERSON_NAME] on the other line. Mm, Yes, I will take it from here. Hello, [PERSON_NAME]. It's nice to have you on the line. My name is [PERSON_NAME] and I am a [OCCUPATION] [OCCUPATION]. So as you stated, [PERSON_NAME], you do have a Medicare with parts A and B riot. Yes. Wonderful. So you are qualified to receive upgraded Medicare benefits. As I can see here, your first name is [PERSON_NAME], your last name is [PERSON_NAME], and your date of birth is [DATE_OF_BIRTH], [DATE_OF_BIRTH], right? Yes. And you currently live in the state of [LOCATION]. Zip code is [LOCATION], correct? Yes. All right, by checking in our database here, Mr. [PERSON_NAME], you're already on a best plan, so I would suggest you to continue with your current plan. Okay? Yes, [PERSON_NAME]. All right. So, by the way, it's nice to have you on the line, Mr. [PERSON_NAME]. Have a wonderful day. Bye.\n",
      "\n",
      "[4] Transcript #3 — cosine=0.6211\n",
      "----------------------------------------------------------------------------------------------------\n",
      "SA Hello? Yeah, miss [PERSON_NAME]. Yes, dear. This is not a new type of insurance and you don't have to pay any kind of additional cost for this. These are some additional Medicare benefits which are going to be added in your plan, okay? And you don't need to worry like you will be receiving all the benefits in written as well so that you can read about it, okay? And it's not going to cost me anything more? No dear, it is at [MONEY_AMOUNT] [MONEY_AMOUNT] premium to you because you are receiving this benefit from our existing plan. As I said, your Medicare is getting upgraded. So Ms. [PERSON_NAME], you don't have to pay any additional cost for this. It is at your [MONEY_AMOUNT] premium to you. Okay, hurry up. Things to do. I listen to phone, I got grandson I need to take care of. Okay? Like Ms. [PERSON_NAME], like this will just take your precious [DURATION] [DURATION] [DURATION] [DURATION] of your time. Like they gonna explain you all the benefits in detail, okay? Okay. Hurry up. So dear, like before getting your call connected, I do believe you have understood that this call is all about traditional Medicare benefits, right? If they're free. If I don't have pay anything. Yeah, here we go. Your call is getting connected. Please stay online and give your precious [DURATION] [DURATION] [DURATION] [DURATION] to them. Hello [PERSON_NAME], thank you for. Hello? Yeah, Miss [PERSON_NAME], I'm there online with you. I'm there online with you. Here we go. I'm just trying to connect your call. Please stay online. Hello, [PERSON_NAME], thank you. Hello? Hi, this is [PERSON_NAME] [PERSON_NAME]. From [ORGANIZATION] [ORGANIZATION]. Am I speaking with [PERSON_NAME] [PERSON_NAME]? Right? Yes. Hi ma' am, how are you today? Okay, you're okay? All right. Again, [PERSON_NAME], I'm from [ORGANIZATION] [ORGANIZATION] [ORGANIZATION] [ORGANIZATION]. Can I confirm your age? How old are you? If you want to tell me more insurance, I have all I need. But ma' am, you can maximize or upgrade. But how about ma' am, you can upgrade or maximize without changing your insurance plan? How is that? Ma' am, would you like to continue? I have Medicare and I have [ORGANIZATION] [ORGANIZATION] [ORGANIZATION]. What else do I need?\n"
     ]
    }
   ],
   "source": [
    "# ==== Main: set inputs (your prompt + client), rank, print, ask Gemini ====\n",
    "\n",
    "# ==== 1) Provide inputs here ====\n",
    "USER_PROMPT = \"What home service does the customer require?\"\n",
    "CLIENT_SELECTOR = 19  # Example: pick customer_id==17 or 17th row if no matching id.\n",
    "\n",
    "# ==== 2) Select the customer and collect doc vectors ====\n",
    "rec = select_customer(records, CLIENT_SELECTOR)\n",
    "doc_texts: List[str] = rec[\"transcripts\"]\n",
    "doc_vecs = np.array(rec[\"embeddings\"], dtype=np.float32)  # shape (4, 3072)\n",
    "\n",
    "# ==== 3) Embed the user prompt and rank the 4 transcripts ====\n",
    "q_vec = embed_prompt(USER_PROMPT)\n",
    "ranking = rank_transcripts_by_cosine(q_vec, doc_vecs)\n",
    "\n",
    "# ==== 4) Print all 4 transcripts in order of similarity ====\n",
    "print_ranked_transcripts(doc_texts, ranking, show_full=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bfae5680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "Gemini answer (using the top-matching transcript as context):\n",
      "====================================================================================================\n",
      "\n",
      "The customer requires service to fix the bracket part around their rearview mirror that is falling down.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==== Build a grounded prompt from the top transcript and call Gemini chat ====\n",
    "\n",
    "best_idx = ranking[0][0]\n",
    "best_transcript = doc_texts[best_idx]\n",
    "\n",
    "# Keep the chat input simple and explicit:\n",
    "chat_input = f\"\"\"\n",
    "You are assisting an internal call-center analysis workflow.\n",
    "\n",
    "User prompt:\n",
    "{USER_PROMPT}\n",
    "\n",
    "Relevant transcript (the most semantically similar of 4 for this customer):\n",
    "{best_transcript}\n",
    "\n",
    "Guidelines:\n",
    "- Rely primarily on the transcript content to answer the user prompt.\n",
    "- If the transcript is missing details the prompt asks for, state what is missing.\n",
    "- Keep the answer crisp and actionable.\n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=CHAT_MODEL,\n",
    "    contents=chat_input\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"Gemini answer (using the top-matching transcript as context):\")\n",
    "print(\"=\"*100 + \"\\n\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de93ca73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemini-chat-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
